{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proyecto utiliza Gradio para crear una interfaz de chat que interactúa con el modelo Llama3.2, permitiendo al usuario hacer preguntas sobre diversos temas. Las respuestas se generan a partir de textos de ejemplo proporcionados, lo que facilita la interacción y consulta directa con el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importa las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "import gradio as gr\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga los pdfs, extraemos los textos y los dividimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se cargaron y dividieron 220 fragmentos de texto.\n"
     ]
    }
   ],
   "source": [
    "pdf_files = [\"documents/pruebaLLM.pdf\",\"documents/pruebaLLM2.pdf\", \"documents/MartinScorsese.pdf\"]  \n",
    "\n",
    "all_documents = []\n",
    "\n",
    "for document in pdf_files:\n",
    "    loader = PyPDFLoader(document) # Carga el documento\n",
    "    data = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=20)    # Divide el texto en chunks\n",
    "    documents = text_splitter.split_documents(data)\n",
    "    all_documents.extend(documents)\n",
    "\n",
    "print(f\"Se cargaron y dividieron {len(all_documents)} fragmentos de texto.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configura un modelo de Hugging Face para generar embeddings de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear un vector store de Chroma usando los documentos y el modelo de embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma.from_documents(\n",
    "    documents=all_documents,\n",
    "    collection_name=\"pdf-prueba6\",\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliza una función de embeddings para representar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = Chroma(\n",
    "    collection_name=\"pdf-prueba6\",\n",
    "    embedding_function=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierte el vector store en un retriever  para realizar consultas basadas en similitud de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Como me llamo?\"\n",
    "docs = vector_store.similarity_search(question,k=10)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos los textos más relacionados a la pregunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 13, 'source': 'documents/MartinScorsese.pdf'}, page_content=\"todo el lirismo, la sutileza y la potencia que se le encomienda. Alo que es preciso añadir los\\natractivosrasgospropiosdelafisonomíaderaízitaliana,queScorseserequeríaparainterpretar\\nelpersonaje de TeresaRonchelli.\\nEN ELNIGHT CLUB\\nElVolpe's, sugiere, entérminosonomásticos, laideadeguarida. Elrefugiodelanimal.\\nRegentadoporTony, elVolpe's es lugardeencuentro de ítalo-norteamericanos. Espartede los\"),\n",
       " Document(metadata={'page': 16, 'source': 'documents/MartinScorsese.pdf'}, page_content='las arenas de unaplaya dorada, desierta, otoñal. Esto es, la luz otorganuevamente a lapareja\\nuna tonalidad onírica. Es la luminosidad del amor, que se asocia a Teresa. Supostura es más\\nlúcida que la de Charlie, quien se compara con San Francisco en su compromiso deproteger.\\nTeresa es en ese momento, un personaje más íntegro, o maduro, que Charlie. Sus apariciones'),\n",
       " Document(metadata={'page': 4, 'source': 'documents/MartinScorsese.pdf'}, page_content='cuando asume que debe seguir la trayectoriacriminal de su padre. Siendo un Corleone no hay\\nescapatoria. Eraunafamiliaperversa,agregaScorsese,\"determinadaporelmiedoydestrozada\\npor la traición, pero estabas en ella sin ni siquiera cuestionar su legitimidad. La organización\\nera unestadodentrodel Estado. El gángstererael directordel consejoyel crimense convirtió\\nen un modo de\\nvida\"'),\n",
       " Document(metadata={'page': 17, 'source': 'documents/MartinScorsese.pdf'}, page_content='en la cocina del restaurante, se devela el punto\\nmásalto de sucrisis. Porunlado, eltíole ofrece\\nel restaurante con la condición de alejarse de\\nTeresayJohny. Porotro, Charlieno es capazde\\nromper con Teresa ni de abandonar a Johnny.\\nAún más, queda de manifiesto su confusión al\\narrepentirse de haber seducido a Diane, la bailarina de color, abortando la cita en el último'),\n",
       " Document(metadata={'page': 2, 'source': 'documents/MartinScorsese.pdf'}, page_content='marcó,yaún lohace\". Dobledimensión:porunapartelasvivenciascomounodelosprincipios\\nque potencian la gestión creadora. Por otra, eljuicio analítico del material cinematográfico.\\nInstancia cultural, inserta en la cinefilia del propio Scorsese, puesta en cuestionamiento al\\ninteriorde supropio discurso.\\nEn el cine de Scorsese laviolencia es parte deun elementopropiciado alavez, porla'),\n",
       " Document(metadata={'page': 17, 'source': 'documents/MartinScorsese.pdf'}, page_content='LuisE. CécéreuLagos ESTUDIOS\\ncuya estructura secuencial da cuenta de las acciones violentas y perturbadoras que enmarca.\\nTodo ello, como se ha dicho, vehiculando la tentativa de Scorsese por situarse en un tono\\ndocumental.\\nSi loreligiosoqueinformalaprocesiónplanteaotroelementodecarácterdual, ésteserá\\nelfactorqueinformadesdeotraperspectiva,ladualidaddeCharlie. Estoes, ladefiniciónde un'),\n",
       " Document(metadata={'page': 11, 'source': 'documents/MartinScorsese.pdf'}, page_content='Scorsese aCorman, en su calidad de productorde BoxearBertha.\\nEl infierno, según Charlie tiene dos penas: la que se puede tocar y la del alma, es\\ndecir, la del espíritu. Pero estátambién laposibilidad de la redención, propia del sentimiento\\ncatólico de Scorsese. Charlie verá su salvación en sucompromiso de amorcon Teresayen la'),\n",
       " Document(metadata={'page': 5, 'source': 'documents/MartinScorsese.pdf'}, page_content='como una sociedad sin estado. En concordancia con las ideas expresadas anteriormente por\\nScorsese, se aprecia que su conocimiento del tema se ajusta a la rigurosa documentación\\ndesplegada en lapreparación de sus obras, como también de los relatos de su padre. Al rigor\\nevidenciado por Marino, en tanto historiador especialista en el tema mencionado, podemos'),\n",
       " Document(metadata={'page': 16, 'source': 'documents/MartinScorsese.pdf'}, page_content='de su percepción de The Little Italy. Deberá recordarse que en el exterior, en la calle, se está\\ndesarrollandolafiestade SanGenaro. Sonelementosmetonímicosqueinformanlacoherencia\\ndel conjunto. Elfilme dacuentade unmodo de ser, de las aristas de unacomunidad, más que\\nde una sociedad. Pero de una comunidad que lleva larvada la violencia como forma de vida.'),\n",
       " Document(metadata={'page': 8, 'source': 'documents/MartinScorsese.pdf'}, page_content='del hogar. \"Cuando era adolescente, en NuevaYork, yo creía que pudiera ser uno de ellos\",\\nenfatizaen el mencionado documental.\\nFelliniseñalaqueélfueunvitellón,unocioso.Comounodelospersonajesdelapelícula,\\nqueestáencarnadoporRoberto, suhermano. Para Fellini, el sueñode losociosos deformalos\\ncontornosdelrecuerdo, endonde lanostalgiadevienepeligrosa, perotambiéncreativa.Esahí,')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea una cadena de procesamiento de lenguaje natural utilizando un LLM local (Ollama) para responder preguntas basadas en un contexto dado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt: Se define una plantilla de pregunta-respuesta que toma un contexto y una pregunta como entrada\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Local LLM: Se configura el modelo llama3.2 para generar respuestas de manera local\n",
    "ollama_llm = \"llama3.2\"\n",
    "model_local = ChatOllama(model=ollama_llm)\n",
    "\n",
    "# Chain Se construye un pipeline que pasa el contexto desde el retriever\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model_local\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulta la base de datos de vectores y devuelve una respuesta utilizando un modelo LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_chroma(input,history):\n",
    "    try:\n",
    "        # Invocar la cadena con la consulta como input\n",
    "        response = chain.invoke(input)\n",
    "        return response  \n",
    "    except Exception as e:\n",
    "        return f\"Error al procesar la consulta: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea una interfaz de chat con Gradio que permite interactuar con el modelo para responder preguntas basadas en textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define la interfaz de chat\n",
    "with gr.Blocks(theme=gr.themes.Glass()) as demo:\n",
    "    gr.Markdown(\"### Chat con llama3.2\")\n",
    "    \n",
    "    # Crea el ChatInterface para manejar la interacción\n",
    "    chat_interface = gr.ChatInterface(fn=search_chroma,type=\"messages\", # The default value (type=\"tuples\") is deprecated \n",
    "                                       examples=[\"Quien es Martin Scorsese\", \"Que relación tiene la violencia es sus películas?\", \"Háblame de Goodfellas\"],\n",
    "                                     )\n",
    "\n",
    "# Lanza la interfaz\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En conclusión, la interfaz de chat con Llama3.2 proporciona una manera sencilla y efectiva de obtener respuestas a preguntas sobre una variedad de temas, utilizando un modelo de lenguaje potente y accesible a través de Gradio. Esto facilita la interacción con el modelo y mejora la experiencia del usuario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
